# Manual discovery
## robots.txt
robots.txt tells engines which pages they are allowed to show on their search engine results.
ex. administration portals or files hosted in the web.

## favicon
We can know the framework the page is using by checking the md5 hash of the favicon (if it hasn't changed, of course, from one of the basic frameworks.)

This is the favicon database:
https://wiki.owasp.org/index.php/OWASP_favicon_database

## sitemap.xml
The sitemap.xml gives a list of everyfile the owner wants to be listed on a search engine.
It's good for areas that are hard to reach or to list some pages that the site no longer uses but work behind the secenes.
reach by <ip>/sitemap.xml
